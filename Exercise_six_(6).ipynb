{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYmVFiEg/hCVcXtYN8LQh+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skolix15/Machine_Learning_2025/blob/main/Exercise_six_(6).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "ePfYBBrGTGqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -U ydata-profiling[notebook]\n",
        "!pip install jupyter-contrib-nbextensions\n",
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "metadata": {
        "id": "NEb-UFz9amOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from ydata_profiling import ProfileReport\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "SV2GtLsAarek"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "SGFz8_rDTtoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "df = pd.read_csv(\"bankloan.csv\")\n",
        "# Create profile report object\n",
        "profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
        "# # Appear to notebook\n",
        "# profile.to_notebook_iframe()\n",
        "# Save to HTML file\n",
        "# profile.to_file(\"notebook_report.html\")"
      ],
      "metadata": {
        "id": "hJuIimKHayqf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "xcdNQO2vTGnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subquestion 1"
      ],
      "metadata": {
        "id": "8OFrHumBUo9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean: 15116.256  \n",
        "\n",
        "Max: 35000\n",
        "\n",
        "Min: 1000"
      ],
      "metadata": {
        "id": "ens88kbWUuSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subquestion 2"
      ],
      "metadata": {
        "id": "2z1P-2taVhjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Μπορούμε να αφαιρέσουμε τις παρακάτω μεταβλητές:\n",
        "\n",
        "(a) Μεταβλητές που λειτουργούν ως αναγνωριστικά =>\n",
        "    1. id (μοναδικές τιμές),\n",
        "    2. mebmer_id (μοναδικές τιμές),\n",
        "    3. row_id (μοναδικές τιμές),\n",
        "    4. unnamed (είναι μη υποστηριζόμενου τύπου και έχει 100% ελλειπούσες τιμές)\n",
        "\n",
        "(b) Μεταβλητές με μεγάλο ποσοστό ελλειπούσων τιμώ =>\n",
        "    5. annual_inc_joint (99.9% ελλειπούσες τιμές)\n",
        "    6. dti_joint (99.9% ελλειπούσες τιμές)\n",
        "    7. 36months (86.1% ελλειπούσες τιμές, είναι υψηλά συσχετισμένη με τις μεταβλητές 60months & term)\n",
        "    8. 60months (86.1% ελλειπούσες τιμές, είναι υψηλά συσχετισμένη με τις μεταβλητές 36months & term)\n",
        "    9. next_pymnt_d (75.5% ελλειπούσες τιμές και μη ισρροπημένο -> 98.8%)\n",
        "    10. mths_since_last_major_derog (71.8% ελλειπούσες τιμές)\n",
        "\n",
        "(c) Μεταβλητές με υψηλή συσχέτιση =>\n",
        "    11. title (υψηλά συσχετισμένη με τη μεταβλητή purpose, μπορεί να αφαιρεθεί διατηρώντας την purpose)\n",
        "    12. grade & sub_grade (υψηλά συσχετισμένες μεταξύ τους. Ενδεχομένως, να αρκούσε η μία από τις δύο)\n",
        "    13. funded_amnt & loan_amnt (υψηλά συσχετισμένες μεταξύ τους. Ενδεχομένως, να αρκούσε η μία από τις δύο)"
      ],
      "metadata": {
        "id": "N7QNbiw9VmK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set variable to drop\n",
        "variables_to_drop = [\n",
        "\n",
        "  # Identifiers/Non-predictive features\n",
        "  'id', 'member_id', 'Row ID', 'Unnamed: 50',\n",
        "\n",
        "  # Variables with high percentage of missing values (>70%)\n",
        "  'annual_inc_joint', 'dti_joint', '36months', '60months',\n",
        "  'next_pymnt_d', 'mths_since_last_major_derog', # ~71.8% missing\n",
        "\n",
        "  # Redundant/Highly correlated variables\n",
        "  'title', 'grade', 'funded_amnt'\n",
        "\n",
        "]\n",
        "\n",
        "# Drop the specified columns from the DataFrame\n",
        "df_cleaned = df.drop(columns=variables_to_drop, axis=1)\n",
        "\n",
        "# Print information\n",
        "print(f\"\\nVariables dropped: {variables_to_drop}\")\n",
        "print(f\"Cleaned DataFrame dimensions: {df_cleaned.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlPLOCIsaIa1",
        "outputId": "0556757e-97e3-44e5-86cf-b96658cd269f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Variables dropped: ['id', 'member_id', 'Row ID', 'Unnamed: 50', 'annual_inc_joint', 'dti_joint', '36months', '60months', 'next_pymnt_d', 'mths_since_last_major_derog', 'title', 'grade', 'funded_amnt']\n",
            "Cleaned DataFrame dimensions: (212999, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subquestion 3"
      ],
      "metadata": {
        "id": "Cp_sp0z0Vij5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill undefined/null values\n",
        "\n",
        "# Get numerical columns\n",
        "numerical_columns = df_cleaned.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Get categorical columns\n",
        "categorical_columns = df_cleaned.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Fill empty numerical columns with mean value\n",
        "for column in numerical_columns:\n",
        "  if df_cleaned[column].isnull().any():\n",
        "          mean_value = df_cleaned[column].mean()\n",
        "          df_cleaned[column].fillna(mean_value)\n",
        "\n",
        "# Fill empty categorical columns with most used value (mode)\n",
        "for column in categorical_columns:\n",
        "    if df_cleaned[column].isnull().any():\n",
        "        # Using .iloc[0] in order to get the first value, in case of multiple modes\n",
        "        mode_value = df_cleaned[column].mode().iloc[0]\n",
        "        df_cleaned[column].fillna(mode_value)\n",
        "\n",
        "# Store updated/cleaned dataframe in new csv file\n",
        "df_cleaned.to_csv(\"bankloan_cleaned.csv\", index=False)\n",
        "print(\"Updated/cleaned Dataframe was stored in 'bankloan_cleaned.csv' file!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFtg6470bjf_",
        "outputId": "c84962a2-d5a9-4472-e8a4-322f0b37d6c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated/cleaned Dataframe was stored in 'bankloan_cleaned.csv' file!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subquestion 4"
      ],
      "metadata": {
        "id": "CryTJOqoVjsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set target values/subgrades\n",
        "target_sub_grades = ['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2']\n",
        "\n",
        "# Create target column with values 0 and 1\n",
        "# Target: 1 => if sub_grade is in target_sub_grades\n",
        "# Target: 0 =>  otherwise\n",
        "df_cleaned['target_loan_risk'] = df_cleaned['sub_grade'].apply(lambda x: 1 if x in target_sub_grades else 0)\n",
        "\n",
        "# Calculate target counts & perchentages\n",
        "target_counts = df_cleaned['target_loan_risk'].value_counts()\n",
        "target_percentages = (df_cleaned['target_loan_risk'].value_counts(normalize=True) * 100).round(2).astype(str) + ' %'\n",
        "\n",
        "# Print results\n",
        "print(f\"Target Counts:\\n{target_counts.to_string(header=False)}\\n\")\n",
        "print(f\"Target Percentages:\\n{target_percentages.to_string(header=False)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNGBwlE1gdRD",
        "outputId": "079daf52-807a-4648-ed66-f1154c45859e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Counts:\n",
            "0    151709\n",
            "1     61290\n",
            "\n",
            "Target Percentages:\n",
            "0    71.23 %\n",
            "1    28.77 %\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Με βάση τα παραπάνω στατιστικά, παρατηρούμε ότι η μεταβλητή target παρουσιάζει σημαντική ανισορροπία. Η κλάση 0 (Υψηλότερος Κίνδυνος/Non-Target) κυριαρχεί με 73.06%, ενώ η κλάση 1 (Χαμηλός Κίνδυνος/Target) αποτελεί τη μειοψηφία (26.94%)."
      ],
      "metadata": {
        "id": "VKuVRf5PnF5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subquestion 5"
      ],
      "metadata": {
        "id": "UgJFHAM8Vk0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ranges (loan_amoun_ranges) of 2000 from the minimum to the maximum loan amount.\n",
        "loan_amount_ranges = range(\n",
        "    int(df_cleaned['loan_amnt'].min()),\n",
        "    int(df_cleaned['loan_amnt'].max()) + 2000,\n",
        "    2000\n",
        ")\n",
        "\n",
        "\n",
        "# Categorize each loan into the corresponding load amount ranges\n",
        "# pd.cut assigns every loan_amnt value to one of the defined intervals.\n",
        "df_cleaned['loan_range'] = pd.cut(df_cleaned['loan_amnt'], loan_amount_ranges)\n",
        "\n",
        "# Calculate approval rate per loan amount range\n",
        "approval_rate = df_cleaned.groupby('loan_range')['target_loan_risk'].mean()\n",
        "\n",
        "# Filter only the intervals where the approval probability\n",
        "# is at least 0.15 (15%).\n",
        "desired_amount_ranges = approval_rate[approval_rate >= 0.15]\n",
        "\n",
        "# Print desired amount ranges\n",
        "print(f\"Desired amount ranges:\\n\\n{desired_amount_ranges}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiCaMPTOC8-N",
        "outputId": "fb62132e-2116-4a2a-c024-71bf3ccf3799"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desired amount ranges:\n",
            "\n",
            "loan_range\n",
            "(1000, 3000]      0.182740\n",
            "(3000, 5000]      0.283272\n",
            "(5000, 7000]      0.347792\n",
            "(7000, 9000]      0.349951\n",
            "(9000, 11000]     0.334011\n",
            "(11000, 13000]    0.294425\n",
            "(13000, 15000]    0.296526\n",
            "(15000, 17000]    0.270516\n",
            "(17000, 19000]    0.262080\n",
            "(19000, 21000]    0.287494\n",
            "(21000, 23000]    0.217605\n",
            "(23000, 25000]    0.322029\n",
            "(25000, 27000]    0.241466\n",
            "(27000, 29000]    0.395797\n",
            "(29000, 31000]    0.173149\n",
            "Name: target_loan_risk, dtype: float64\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3636721772.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  approval_rate = df_cleaned.groupby('loan_range')['target_loan_risk'].mean()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "JNx8oXUiTGiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization Method"
      ],
      "metadata": {
        "id": "k2y-kjCEpDhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Για την κανονικοποίηση των εισόδων στο πρόβλημα πρόβλεψης δανειοδότησης, επέλεξα τη μέθοδο StandardScaler, η οποία μετασχηματίζει κάθε αριθμητική μεταβλητή ώστε να έχει μέση τιμή 0 και τυπική απόκλιση 1. Η επιλογή αυτή έγινε διότι τα χαρακτηριστικά διαφέρουν σημαντικά σε κλίμακα και μονάδες μέτρησης, όπως για παράδειγμα το ποσό δανείου και το ετήσιο εισόδημα. Με αυτόν τον τρόπο τα μοντέλα που βασίζονται σε απόσταση ή gradient, όπως η Logistic Regression, το SVM ή το KNN, μπορούν να συγκρίνουν τις μεταβλητές με ίση βαρύτητα, ενώ ταυτόχρονα διατηρείται η σχετική κατανομή των τιμών και δεν περιορίζονται αυθαίρετα οι ακραίες τιμές, όπως θα συνέβαινε με το MinMaxScaler."
      ],
      "metadata": {
        "id": "AwQHudWuE4Qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source Code"
      ],
      "metadata": {
        "id": "UdLc2zjqpP7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 0) Precondition: df_cleaned exists and 'sub_grade' & 'target_loan_risk' present ----\n",
        "# Drop leakage\n",
        "df_model = df_cleaned.drop(columns=['sub_grade'], axis=1)\n",
        "\n",
        "# Features / target\n",
        "X = df_model.drop(columns=['target_loan_risk'])\n",
        "y = df_model['target_loan_risk']\n",
        "\n",
        "# Identify feature types\n",
        "num_features = X.select_dtypes(include=['number']).columns.tolist()\n",
        "cat_features = X.select_dtypes(include=['object','category']).columns.tolist()\n",
        "\n",
        "# --- 1) Build preprocessing pipelines ---\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),   # fill numeric NaNs\n",
        "    ('scaler', StandardScaler())                     # normalize -> mean=0, std=1\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # fill categorical NaNs\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True, drop='first'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_pipeline, num_features),\n",
        "        ('cat', categorical_pipeline, cat_features)\n",
        "    ],\n",
        "    # preserve sparse output if many features are sparse; leave default sparse_threshold\n",
        ")\n",
        "\n",
        "# --- 2) Full pipeline with RandomForest ---\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "pipeline = Pipeline([\n",
        "    ('preproc', preprocessor),\n",
        "    ('clf', rf)\n",
        "])\n",
        "\n",
        "# --- 3) Train/test split (stratify) ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 4) GridSearch (light) on n_estimators ---\n",
        "param_grid = {'clf__n_estimators': [50, 100]}  # keep small for Colab\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# --- 5) Evaluate on test set ---\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Accuracy : \", round(accuracy_score(y_test, y_pred), 3))\n",
        "print(\"Precision: \", round(precision_score(y_test, y_pred), 3))\n",
        "print(\"Recall   : \", round(recall_score(y_test, y_pred), 3))\n",
        "print(\"F1-score : \", round(f1_score(y_test, y_pred), 3))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8Wsh-QkEZK0",
        "outputId": "d93adaf2-6020-4eac-c311-f693aa955776"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [1, 8] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'clf__n_estimators': 100}\n",
            "Accuracy :  0.995\n",
            "Precision:  1.0\n",
            "Recall   :  0.984\n",
            "F1-score :  0.992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifiter Selection"
      ],
      "metadata": {
        "id": "KJKdbHdMo0xk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Επέλεξα RandomForest γιατί το dataset είναι μεγάλο και περιέχει τόσο αριθμητικά όσο και κατηγορικά χαρακτηριστικά. Το RandomForest ανιχνεύει μη γραμμικές σχέσεις, είναι ανθεκτικό σε outliers, και συνήθως έχει καλύτερη απόδοση σε πολύπλοκα datasets. Η παράμετρος n_estimators ρυθμίστηκε μέσω cross-validation, καθώς είναι η πιο ευαίσθητη παράμετρος για το μοντέλο."
      ],
      "metadata": {
        "id": "jSTH3ICZoXiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Most crucial metric"
      ],
      "metadata": {
        "id": "GaxBZthio3-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Η πιο σημαντική μετρική για αυτή την εφαρμογή είναι το F1-score, καθώς εξισορροπεί Precision και Recall. Εναλλακτικά, ανάλογα με την προτεραιότητα της τράπεζας, μπορούμε να δώσουμε μεγαλύτερη έμφαση στο Precision για να ελαχιστοποιήσουμε τον κίνδυνο κακών δανειοληπτών."
      ],
      "metadata": {
        "id": "_F9203ceozZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "hU8G9FhdTGC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5"
      ],
      "metadata": {
        "id": "REjuKntkTyH3"
      }
    }
  ]
}